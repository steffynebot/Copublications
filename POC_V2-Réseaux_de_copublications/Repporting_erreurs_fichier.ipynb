{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d23582f-32c5-46c2-9ae7-66d1c5fe2124",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c899f7ab-214d-47c0-bbb3-f1538f0e9df8",
   "metadata": {},
   "source": [
    "# Analyse du fichier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d78b7-cfa2-4ed1-be4e-9cc30eefd693",
   "metadata": {},
   "source": [
    "1Ô∏è‚É£ Chargement CSV robuste (encodage + s√©parateur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab001808-016f-410f-82bd-1a5e14af3d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_safely(path: Path) -> pd.DataFrame:\n",
    "    encodings = [\"utf-8\", \"utf-8-sig\", \"latin1\"]\n",
    "    seps = [\",\", \";\", \"\\t\"]\n",
    "\n",
    "    for enc in encodings:\n",
    "        for sep in seps:\n",
    "            try:\n",
    "                df = pd.read_csv(\n",
    "                    path,\n",
    "                    encoding=enc,\n",
    "                    sep=sep,\n",
    "                    engine=\"python\",\n",
    "                    on_bad_lines=\"skip\",\n",
    "                )\n",
    "                print(f\"‚úÖ CSV charg√© | enc={enc} | sep='{sep}'\")\n",
    "                return df\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    raise RuntimeError(\"‚ùå Impossible de lire le CSV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f40d5-82b9-4695-9e6a-a1f37e31a573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSV charg√© | enc=latin1 | sep=','\n",
      "(32084, 1)\n"
     ]
    }
   ],
   "source": [
    "df = load_csv_safely(r\"C:\\Users\\abapst\\nb_python\\copublication_italie\\ITALIE\\plotly2\\Copublis_Internationales_Inria_nov_2025_complet.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac4b432-0f26-40cb-b49c-6727460d3da6",
   "metadata": {},
   "source": [
    "2Ô∏è‚É£ Normalisation des noms de colonnes (camelCase ASCII)\n",
    "\n",
    "Adapter le nom des colonnes en camelCase sans caract√®res sp√©ciaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81223122-2a93-44ea-8866-7fb43e05b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(col: str) -> str:\n",
    "    col = unicodedata.normalize(\"NFKD\", col)\n",
    "    col = col.encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "    col = re.sub(r\"[^\\w\\s]\", \"\", col)\n",
    "    parts = col.strip().split()\n",
    "    return parts[0].lower() + \"\".join(p.capitalize() for p in parts[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a182d27f-bbf3-4bfa-853e-c9c19e2461f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['centreequipeauteursFrauteursCopubliantsorganismeCopubliantadressevillepaysidAurehaluenonUeanneehaliddomainesdomainesConsolidesmotsclesresumelatitudelongitudegeonameid']\n"
     ]
    }
   ],
   "source": [
    "df.columns = [normalize_column(c) for c in df.columns]\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ffe5ba-32d7-445d-b970-d892fa4439c4",
   "metadata": {},
   "source": [
    "3Ô∏è‚É£ Nettoyage des villes et organismes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb0d6b8-dc71-49da-a520-11d48beab87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_city(city):\n",
    "    if pd.isna(city):\n",
    "        return None\n",
    "\n",
    "    city = city.strip()\n",
    "\n",
    "    if city.upper() in {\"ANL\", \"??\", \"???\", \"N/A\"}:\n",
    "        return None\n",
    "\n",
    "    city = re.sub(r\"\\d+\", \"\", city)\n",
    "    city = re.sub(r\"[^\\w\\s-]\", \"\", city)\n",
    "\n",
    "    city = unicodedata.normalize(\"NFKD\", city)\n",
    "    city = city.encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "\n",
    "    city = re.sub(r\"\\s+\", \" \", city).strip()\n",
    "\n",
    "    return city if len(city) > 1 else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a8f0fa-12e9-4578-a5a5-987eebb41016",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Ville\" in df.columns:\n",
    "    df[\"villeClean\"] = df[\"Ville\"].apply(clean_city)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88954dc6-604a-4570-bdc7-1903e8bce8ab",
   "metadata": {},
   "source": [
    "Nettoyage des organismes copubliants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad15b1-3e4b-45e1-b172-de1d3cce8afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_org(org):\n",
    "    if pd.isna(org):\n",
    "        return None\n",
    "    org = re.sub(r\"[\\[\\]\\?]\", \"\", org)\n",
    "    return re.sub(r\"\\s+\", \" \", org).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85487e7-40cb-48e6-9d93-bc1439e06939",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Organisme_copubliant\" in df.columns:\n",
    "    df[\"organismeCopubliantClean\"] = df[\"Organisme_copubliant\"].apply(clean_org)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33595a77-0f08-4040-a7d5-95d468ffc63d",
   "metadata": {},
   "source": [
    "4Ô∏è‚É£ Mise √† jour des domaines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f4d02-63c5-4e48-a90b-432f4f99c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Domaine(s)\" in df.columns:\n",
    "    df[\"Domaine(s)\"] = (\n",
    "        df[\"Domaine(s)\"]\n",
    "        .astype(str)\n",
    "        .str.replace(r\"[^\\w\\s;/]\", \"\", regex=True)\n",
    "        .str.strip()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5a897e-355d-42d7-9edc-493f401de36d",
   "metadata": {},
   "source": [
    "5Ô∏è‚É£ Validation g√©ographique AVANT g√©ocodage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc452d69-c7cd-44f2-a2f7-0869b9065ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_diagnostics(df):\n",
    "    print(\"\\nüó∫Ô∏è DIAGNOSTICS G√âO\")\n",
    "\n",
    "    if not {\"Latitude\", \"Longitude\"} <= set(df.columns):\n",
    "        print(\"‚ö†Ô∏è Pas de colonnes latitude/longitude\")\n",
    "        return\n",
    "\n",
    "    invalid = df[\n",
    "        (df[\"Latitude\"].abs() > 90) | (df[\"Longitude\"].abs() > 180)\n",
    "    ]\n",
    "    print(\"Coordonn√©es invalides :\", len(invalid))\n",
    "\n",
    "    missing = df[\n",
    "        df[\"villeClean\"].notna()\n",
    "        & (df[\"Latitude\"].isna() | df[\"Longitude\"].isna())\n",
    "    ]\n",
    "    print(\"Villes sans coordonn√©es :\", len(missing))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e18eb8c-9d40-492b-b498-33e37c57fa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üó∫Ô∏è DIAGNOSTICS G√âO\n",
      "‚ö†Ô∏è Pas de colonnes latitude/longitude\n"
     ]
    }
   ],
   "source": [
    "geo_diagnostics(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea8e0dc-4c96-4089-acbc-c7f67c02d3ea",
   "metadata": {},
   "source": [
    "6Ô∏è‚É£ G√©ocodage Nominatim avec cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807263d2-eac7-49e2-986e-1caf90551f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cache():\n",
    "    if CACHE_PATH.exists():\n",
    "        return json.loads(CACHE_PATH.read_text(encoding=\"utf-8\"))\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache):\n",
    "    CACHE_PATH.write_text(\n",
    "        json.dumps(cache, indent=2, ensure_ascii=False),\n",
    "        encoding=\"utf-8\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84970d7-865d-4e62-8807-c946a789e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nominatim(city, country=None):\n",
    "    url = \"https://nominatim.openstreetmap.org/search\"\n",
    "    params = {\"city\": city, \"format\": \"json\", \"limit\": 1}\n",
    "    if country:\n",
    "        params[\"country\"] = country\n",
    "\n",
    "    headers = {\"User-Agent\": \"INRIA-Geocoder/1.0\"}\n",
    "    time.sleep(1.1)\n",
    "\n",
    "    r = requests.get(url, params=params, headers=headers, timeout=20)\n",
    "    if r.status_code != 200 or not r.json():\n",
    "        return None\n",
    "\n",
    "    res = r.json()[0]\n",
    "    return float(res[\"lat\"]), float(res[\"lon\"]), float(res.get(\"importance\", 0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738ad76-0277-462c-8db5-90c658479066",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CACHE_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cache \u001b[38;5;241m=\u001b[39m load_cache()\n\u001b[0;32m      3\u001b[0m lat_geo, lon_geo, source, conf, status \u001b[38;5;241m=\u001b[39m [], [], [], [], []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n",
      "Cell \u001b[1;32mIn[45], line 2\u001b[0m, in \u001b[0;36mload_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_cache\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m CACHE_PATH\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(CACHE_PATH\u001b[38;5;241m.\u001b[39mread_text(encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CACHE_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "cache = load_cache()\n",
    "\n",
    "lat_geo, lon_geo, source, conf, status = [], [], [], [], []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    city = row.get(\"villeClean\")\n",
    "    country = row.get(\"Pays\")\n",
    "\n",
    "    if pd.notna(row.get(\"Latitude\")) and pd.notna(row.get(\"Longitude\")):\n",
    "        lat_geo.append(row[\"Latitude\"])\n",
    "        lon_geo.append(row[\"Longitude\"])\n",
    "        source.append(\"existing\")\n",
    "        conf.append(1.0)\n",
    "        status.append(\"ok\")\n",
    "        continue\n",
    "\n",
    "    if not city:\n",
    "        lat_geo.append(None)\n",
    "        lon_geo.append(None)\n",
    "        source.append(None)\n",
    "        conf.append(0.0)\n",
    "        status.append(\"missing\")\n",
    "        continue\n",
    "\n",
    "    key = f\"{city}|{country}\"\n",
    "\n",
    "    if key in cache:\n",
    "        lat, lon, c = cache[key]\n",
    "        lat_geo.append(lat)\n",
    "        lon_geo.append(lon)\n",
    "        source.append(\"cache\")\n",
    "        conf.append(c)\n",
    "        status.append(\"ok\")\n",
    "        continue\n",
    "\n",
    "    res = nominatim(city, country)\n",
    "    if res:\n",
    "        lat, lon, c = res\n",
    "        cache[key] = (lat, lon, c)\n",
    "        lat_geo.append(lat)\n",
    "        lon_geo.append(lon)\n",
    "        source.append(\"nominatim\")\n",
    "        conf.append(c)\n",
    "        status.append(\"ok\")\n",
    "    else:\n",
    "        lat_geo.append(None)\n",
    "        lon_geo.append(None)\n",
    "        source.append(\"nominatim\")\n",
    "        conf.append(0.0)\n",
    "        status.append(\"ambiguous\")\n",
    "\n",
    "save_cache(cache)\n",
    "\n",
    "df[\"latitudeGeo\"] = lat_geo\n",
    "df[\"longitudeGeo\"] = lon_geo\n",
    "df[\"geoSource\"] = source\n",
    "df[\"geoConfidence\"] = conf\n",
    "df[\"geoStatus\"] = status\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49063330-6e36-4194-a3e9-f132d2640de8",
   "metadata": {},
   "source": [
    "7Ô∏è‚É£ Pr√©-agr√©gations Dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c74950d-687a-4900-b628-dfa20da2cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_pays = df.groupby(\"Pays\").size().reset_index(name=\"nbPublications\")\n",
    "agg_annee = df.groupby(\"Ann√©e\").size().reset_index(name=\"nbPublications\")\n",
    "agg_ue = df.groupby(\"UE/Non_UE\").size().reset_index(name=\"nbPublications\")\n",
    "agg_ville = (\n",
    "    df[df[\"geoStatus\"] == \"ok\"]\n",
    "    .groupby([\"villeClean\", \"latitudeGeo\", \"longitudeGeo\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"nbPublications\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26b2a8e-a58e-4d28-b4c7-ef5c3e707d5d",
   "metadata": {},
   "source": [
    "8Ô∏è‚É£ Tests rapides (qualit√© minimale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2683c5-ccc1-44cd-9ff8-b634a1847a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df[\"villeClean\"].isna().mean() < 0.3, \"‚ö†Ô∏è Trop de villes invalides\"\n",
    "assert (df[\"geoStatus\"] == \"ok\").mean() > 0.6, \"‚ö†Ô∏è G√©ocodage insuffisant\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302b0871-3b16-4b47-a297-06ff6749f89e",
   "metadata": {},
   "source": [
    "9Ô∏è‚É£ Export final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c4407-608f-4c17-85fa-6944f4e755d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{OUTPUT_PREFIX}.csv\", sep=\";\", encoding=\"utf-8\", index=False)\n",
    "df.to_parquet(f\"{OUTPUT_PREFIX}.parquet\", index=False)\n",
    "\n",
    "agg_pays.to_csv(\"agg_pays.csv\", index=False)\n",
    "agg_annee.to_csv(\"agg_annee.csv\", index=False)\n",
    "agg_ville.to_parquet(\"agg_ville.parquet\", index=False)\n",
    "\n",
    "print(\"‚úÖ PIPELINE TERMIN√â AVEC SUCC√àS\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570bb54a-fa21-48ee-96e2-edc716ca248c",
   "metadata": {},
   "source": [
    "# üîú 2. Cr√©ation du rapport PDF\n",
    "\n",
    "Pour le rapport PDF automatique, voici la fonction qui g√©n√®re une documentation sur le pipeline, en tenant compte des √©tapes pr√©c√©dentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaf6a83-f573-4d20-ae1f-6f191d2b37f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue PDF generation code\n",
    "\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.pagesizes import A4\n",
    "\n",
    "def generate_pdf_report(df):\n",
    "    output_pdf = \"pipeline_report.pdf\"\n",
    "    doc = SimpleDocTemplate(output_pdf, pagesize=A4)\n",
    "    story = []\n",
    "    styles = getSampleStyleSheet()\n",
    "\n",
    "    def add_title(text):\n",
    "        story.append(Paragraph(f\"<b><font size=16>{text}</font></b>\", styles[\"Title\"]))\n",
    "        story.append(Spacer(1, 12))\n",
    "\n",
    "    def add_section(title, body):\n",
    "        story.append(Paragraph(f\"<b>{title}</b>\", styles[\"Heading2\"]))\n",
    "        story.append(Spacer(1, 6))\n",
    "        for line in body.split(\"\\n\"):\n",
    "            story.append(Paragraph(line, styles[\"Normal\"]))\n",
    "        story.append(Spacer(1, 12))\n",
    "\n",
    "    add_title(\"Rapport du Pipeline de Nettoyage et G√©ocodage\")\n",
    "\n",
    "    add_section(\"R√©sum√©\", f\"\"\"\n",
    "    Nombre total de lignes : {len(df)}\n",
    "    Colonnes disponibles : {len(df.columns)}\n",
    "    Taux de g√©ocodage OK : {(df['geoStatus']=='ok').mean():.2%}\n",
    "    \"\"\")\n",
    "\n",
    "    add_section(\"G√©ocodage\", f\"\"\"\n",
    "    Sources :\n",
    "    - Existing : {(df['geoSource']=='existing').mean():.2%}\n",
    "    - Cache : {(df['geoSource']=='cache').mean():.2%}\n",
    "    - Nominatim : {(df['geoSource']=='nominatim').mean():.2%}\n",
    "\n",
    "    Cas ambigus : {(df['geoStatus']=='ambiguous').sum()}\n",
    "    \"\"\")\n",
    "\n",
    "    add_section(\"Qualit√© des donn√©es\", f\"\"\"\n",
    "    Villes nettoy√©es manquantes : {df['villeClean'].isna().sum()}\n",
    "    Organismes nettoy√©s manquants : {df['organismeCopubliantClean'].isna().sum()}\n",
    "    \"\"\")\n",
    "\n",
    "    doc.build(story)\n",
    "    print(f\"üìÑ Rapport PDF g√©n√©r√© : {output_pdf}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937df243-76e6-440a-8d11-817ecfbc65b5",
   "metadata": {},
   "source": [
    "#  DASH APP (branch√©e DIRECTEMENT sur mes donn√©es)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254abb52-3d11-4786-946f-af056d13abb8",
   "metadata": {},
   "source": [
    "pipeline/\n",
    "‚îú‚îÄ‚îÄ pipeline_notebook.ipynb   ‚Üê ex√©cution principale\n",
    "‚îú‚îÄ‚îÄ dash_app.py               ‚Üê dashboard Plotly Dash\n",
    "‚îú‚îÄ‚îÄ report.py                 ‚Üê g√©n√©ration PDF\n",
    "‚îú‚îÄ‚îÄ tests/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ test_villes.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ test_organismes.py\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ test_geo.py\n",
    "‚îî‚îÄ‚îÄ geocode_cache.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d8bb81-9585-42c6-b21d-88ef6ccb3319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"Copublications_INRIA_clean.parquet\")\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Copublications internationales INRIA\"),\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id=\"ue_filter\",\n",
    "        options=[{\"label\": v, \"value\": v} for v in df[\"UE/Non_UE\"].dropna().unique()],\n",
    "        multi=True,\n",
    "        placeholder=\"UE / Non UE\"\n",
    "    ),\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id=\"year_filter\",\n",
    "        options=[{\"label\": int(y), \"value\": int(y)} for y in sorted(df[\"Ann√©e\"].dropna().unique())],\n",
    "        multi=True,\n",
    "        placeholder=\"Ann√©e\"\n",
    "    ),\n",
    "\n",
    "    dcc.Graph(id=\"map\"),\n",
    "    dcc.Graph(id=\"by_country\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de80ba13-bf5f-4acc-a6cf-6831305b30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    [Output(\"map\", \"figure\"),\n",
    "     Output(\"by_country\", \"figure\")],\n",
    "    [Input(\"ue_filter\", \"value\"),\n",
    "     Input(\"year_filter\", \"value\")]\n",
    ")\n",
    "def update_graphs(ue, years):\n",
    "    dff = df.copy()\n",
    "\n",
    "    if ue:\n",
    "        dff = dff[dff[\"UE/Non_UE\"].isin(ue)]\n",
    "    if years:\n",
    "        dff = dff[dff[\"Ann√©e\"].isin(years)]\n",
    "\n",
    "    map_fig = px.scatter_geo(\n",
    "        dff[dff[\"geoStatus\"] == \"ok\"],\n",
    "        lat=\"latitudeGeo\",\n",
    "        lon=\"longitudeGeo\",\n",
    "        size=dff.groupby(\"Ville\").transform(\"size\"),\n",
    "        hover_name=\"Ville\",\n",
    "        title=\"Carte des copublications\"\n",
    "    )\n",
    "\n",
    "    country_fig = px.bar(\n",
    "        dff.groupby(\"Pays\").size().reset_index(name=\"n\"),\n",
    "        x=\"Pays\",\n",
    "        y=\"n\",\n",
    "        title=\"Publications par pays\"\n",
    "    )\n",
    "\n",
    "    return map_fig, country_fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0b4b7-0e36-40d9-8837-2cd6bf861dd2",
   "metadata": {},
   "source": [
    "RAPPORT PDF AUTOMATIQUE (STATISTIQUES R√âELLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef5ffa-f4e2-4a6a-be75-bc5d50a914f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.pagesizes import A4\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"Copublications_INRIA_clean.parquet\")\n",
    "\n",
    "doc = SimpleDocTemplate(\"rapport_pipeline_INRIA.pdf\", pagesize=A4)\n",
    "styles = getSampleStyleSheet()\n",
    "story = []\n",
    "\n",
    "def add(title, text):\n",
    "    story.append(Paragraph(f\"<b>{title}</b>\", styles[\"Heading2\"]))\n",
    "    story.append(Spacer(1, 6))\n",
    "    story.append(Paragraph(text, styles[\"Normal\"]))\n",
    "    story.append(Spacer(1, 12))\n",
    "\n",
    "story.append(Paragraph(\"<b>Rapport de traitement des copublications</b>\", styles[\"Title\"]))\n",
    "\n",
    "add(\"Vue d'ensemble\", f\"\"\"\n",
    "Nombre total de lignes : {len(df)}<br/>\n",
    "Ann√©es couvertes : {int(df['Ann√©e'].min())} ‚Äì {int(df['Ann√©e'].max())}<br/>\n",
    "Taux de g√©ocodage valide : {(df['geoStatus']=='ok').mean():.2%}\n",
    "\"\"\")\n",
    "\n",
    "add(\"G√©ocodage\", f\"\"\"\n",
    "Sources utilis√©es :<br/>\n",
    "- Coordonn√©es existantes : {(df['geoSource']=='existing').mean():.2%}<br/>\n",
    "- Cache : {(df['geoSource']=='cache').mean():.2%}<br/>\n",
    "- Nominatim : {(df['geoSource']=='nominatim').mean():.2%}<br/>\n",
    "Cas ambigus : {(df['geoStatus']=='ambiguous').sum()}\n",
    "\"\"\")\n",
    "\n",
    "add(\"Qualit√© des donn√©es\", f\"\"\"\n",
    "Villes non exploitables : {df['villeClean'].isna().sum()}<br/>\n",
    "Organismes nettoy√©s manquants : {df['organismeCopubliantClean'].isna().sum()}\n",
    "\"\"\")\n",
    "\n",
    "doc.build(story)\n",
    "print(\"üìÑ Rapport PDF g√©n√©r√© : rapport_pipeline_INRIA.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2443d561-8983-43af-aaa8-2a1a800b7a52",
   "metadata": {},
   "source": [
    "TESTS UNITAIRES (pytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0695ed1-d71f-40d5-80fc-becaa0b5854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests/test_villes.py\n",
    "from pipeline_notebook import clean_city\n",
    "\n",
    "def test_city_cleaning():\n",
    "    assert clean_city(\" Paris \") == \"Paris\"\n",
    "    assert clean_city(\"???\") is None\n",
    "    assert clean_city(\"ANL\") is None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c503c51-1f73-4a0a-9b64-69052496bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests/test_organismes.py\n",
    "from pipeline_notebook import clean_org\n",
    "\n",
    "def test_org_cleaning():\n",
    "    assert clean_org(\"INRIA [Paris]?\") == \"INRIA Paris\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc23875-05bc-457e-b8bd-7a6943c01029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests/test_geo.py\n",
    "def test_coordinates_range():\n",
    "    from pipeline_notebook import geo_diagnostics\n",
    "    assert -90 <= 48.8 <= 90\n",
    "    assert -180 <= 2.3 <= 180"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dash_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
